Description:
- 20231109-154208-pr
Torch version: 2.2.0a0+gita310cc8
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_89,code=sm_89
  - CuDNN 8.9
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.2.0, USE_CUDA=1, USE_CUDNN=1, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=0, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 


- 20231109-110115-nightly
Torch version: 2.2.0a0+git3ca81ae
Torch config: PyTorch built with:
  - GCC 9.4
  - C++ Version: 201703
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_89,code=sm_89
  - CuDNN 8.9
  - Build settings: BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_PYTORCH_QNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.2.0, USE_CUDA=1, USE_CUDNN=1, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=OFF, USE_MKLDNN=0, USE_MPI=OFF, USE_NCCL=0, USE_NNPACK=0, USE_OPENMP=ON, USE_ROCM=OFF, 



[-------------------------------------------------------------------------- Affine grid sampling, cpu --------------------------------------------------------------------------]
                                                                                                          |  Eager (2.2.0a0+gita310cc8) PR  |  Eager (2.2.0a0+git3ca81ae) nightly
1 threads: ----------------------------------------------------------------------------------------------------------------------------------------------------------------------
      Input: (1, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=True, mode=nearest    |        635.152 (+-4.573)        |         1196.590 (+-16.223)        
      Input: (1, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=True, mode=nearest    |       1318.168 (+-73.817)       |         2658.933 (+-62.208)        
      Input: (1, 3, 500, 400) torch.float32, torch.channels_last, align_corners=True, mode=nearest        |        542.311 (+-3.712)        |         1166.259 (+-13.349)        
      Input: (1, 3, 500, 400) torch.float64, torch.channels_last, align_corners=True, mode=nearest        |       1051.112 (+-30.105)       |         2472.511 (+-37.322)        
      Input: (1, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=False, mode=nearest   |        650.230 (+-3.444)        |         1211.040 (+-15.933)        
      Input: (1, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=False, mode=nearest   |       1440.749 (+-94.342)       |         2680.096 (+-72.214)        
      Input: (1, 3, 500, 400) torch.float32, torch.channels_last, align_corners=False, mode=nearest       |        553.308 (+-4.068)        |         1165.713 (+-13.829)        
      Input: (1, 3, 500, 400) torch.float64, torch.channels_last, align_corners=False, mode=nearest       |       1134.787 (+-38.471)       |         2479.525 (+-37.279)        
      Input: (1, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=True, mode=bilinear   |       1299.496 (+-14.302)       |         3713.318 (+-53.087)        
      Input: (1, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=True, mode=bilinear   |       2538.610 (+-67.672)       |         6266.618 (+-70.403)        
      Input: (1, 3, 500, 400) torch.float32, torch.channels_last, align_corners=True, mode=bilinear       |       1054.289 (+-13.182)       |         3689.232 (+-35.200)        
      Input: (1, 3, 500, 400) torch.float64, torch.channels_last, align_corners=True, mode=bilinear       |       2211.281 (+-47.284)       |         6053.448 (+-43.859)        
      Input: (1, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=False, mode=bilinear  |       1339.189 (+-38.475)       |         3695.113 (+-48.203)        
      Input: (1, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=False, mode=bilinear  |       2577.862 (+-54.038)       |         6244.574 (+-66.058)        
      Input: (1, 3, 500, 400) torch.float32, torch.channels_last, align_corners=False, mode=bilinear      |       1075.366 (+-16.101)       |         3680.292 (+-35.145)        
      Input: (1, 3, 500, 400) torch.float64, torch.channels_last, align_corners=False, mode=bilinear      |       2166.130 (+-61.954)       |         6073.101 (+-99.366)        
      Input: (1, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=True, mode=bicubic    |       4650.900 (+-36.131)       |        14703.326 (+-564.378)       
      Input: (1, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=True, mode=bicubic    |      30225.786 (+-593.286)      |        38338.429 (+-768.288)       
      Input: (1, 3, 500, 400) torch.float32, torch.channels_last, align_corners=True, mode=bicubic        |       4272.110 (+-40.117)       |        14766.649 (+-260.509)       
      Input: (1, 3, 500, 400) torch.float64, torch.channels_last, align_corners=True, mode=bicubic        |      28972.281 (+-595.555)      |        37420.822 (+-785.526)       
      Input: (1, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=False, mode=bicubic   |       4632.845 (+-39.276)       |        14704.016 (+-330.618)       
      Input: (1, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=False, mode=bicubic   |      30133.470 (+-813.745)      |        38409.600 (+-691.079)       
      Input: (1, 3, 500, 400) torch.float32, torch.channels_last, align_corners=False, mode=bicubic       |       4270.568 (+-50.004)       |        14756.324 (+-236.034)       
      Input: (1, 3, 500, 400) torch.float64, torch.channels_last, align_corners=False, mode=bicubic       |      29147.480 (+-662.822)      |        37389.990 (+-663.702)       
      Input: (8, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=True, mode=nearest    |       9627.674 (+-96.119)       |        13726.028 (+-112.412)       
      Input: (8, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=True, mode=nearest    |      33495.450 (+-256.940)      |        41501.452 (+-327.186)       
      Input: (8, 3, 500, 400) torch.float32, torch.channels_last, align_corners=True, mode=nearest        |       7520.504 (+-77.904)       |         10839.269 (+-93.029)       
      Input: (8, 3, 500, 400) torch.float64, torch.channels_last, align_corners=True, mode=nearest        |      27361.331 (+-239.124)      |        34985.201 (+-350.970)       
      Input: (8, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=False, mode=nearest   |       9650.794 (+-108.986)      |        13858.466 (+-128.411)       
      Input: (8, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=False, mode=nearest   |      33396.135 (+-276.450)      |        41104.817 (+-433.195)       
      Input: (8, 3, 500, 400) torch.float32, torch.channels_last, align_corners=False, mode=nearest       |       7607.175 (+-57.570)       |         10916.952 (+-96.023)       
      Input: (8, 3, 500, 400) torch.float64, torch.channels_last, align_corners=False, mode=nearest       |      27666.219 (+-163.821)      |        34851.453 (+-260.788)       
      Input: (8, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=True, mode=bilinear   |      14272.830 (+-129.055)      |        36243.299 (+-350.811)       
      Input: (8, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=True, mode=bilinear   |      39781.618 (+-212.984)      |        68053.260 (+-1057.869)      
      Input: (8, 3, 500, 400) torch.float32, torch.channels_last, align_corners=True, mode=bilinear       |      11140.157 (+-189.204)      |        30729.080 (+-381.639)       
      Input: (8, 3, 500, 400) torch.float64, torch.channels_last, align_corners=True, mode=bilinear       |      21513.122 (+-144.430)      |        63030.143 (+-390.692)       
      Input: (8, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=False, mode=bilinear  |      14439.778 (+-104.451)      |        36150.986 (+-293.416)       
      Input: (8, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=False, mode=bilinear  |      39987.657 (+-187.156)      |        67757.076 (+-991.072)       
      Input: (8, 3, 500, 400) torch.float32, torch.channels_last, align_corners=False, mode=bilinear      |      11412.859 (+-135.364)      |        30465.192 (+-282.936)       
      Input: (8, 3, 500, 400) torch.float64, torch.channels_last, align_corners=False, mode=bilinear      |      35486.925 (+-351.209)      |        63729.695 (+-678.976)       
      Input: (8, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=True, mode=bicubic    |      39349.091 (+-307.515)      |       129854.028 (+-1635.314)      
      Input: (8, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=True, mode=bicubic    |     266975.403 (+-7133.165)     |       352072.211 (+-3178.250)      
      Input: (8, 3, 500, 400) torch.float32, torch.channels_last, align_corners=True, mode=bicubic        |      35676.285 (+-383.030)      |       126762.714 (+-1740.266)      
      Input: (8, 3, 500, 400) torch.float64, torch.channels_last, align_corners=True, mode=bicubic        |     275259.573 (+-2487.939)     |       341804.886 (+-2974.238)      
      Input: (8, 3, 500, 400) torch.float32, torch.contiguous_format, align_corners=False, mode=bicubic   |      39590.653 (+-314.655)      |       130436.644 (+-3081.411)      
      Input: (8, 3, 500, 400) torch.float64, torch.contiguous_format, align_corners=False, mode=bicubic   |     284594.849 (+-2782.160)     |       353432.316 (+-3600.725)      
      Input: (8, 3, 500, 400) torch.float32, torch.channels_last, align_corners=False, mode=bicubic       |      35751.563 (+-385.507)      |       126884.936 (+-1718.414)      
      Input: (8, 3, 500, 400) torch.float64, torch.channels_last, align_corners=False, mode=bicubic       |     275082.382 (+-2370.073)     |       326207.948 (+-2578.309)      

Times are in microseconds (us).
